{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Access Management 101\n",
    "\n",
    "IAM - allows you to manage users and their level of access to the AWS console.\n",
    "\n",
    "It is important to understand IAM and how it works, both for the exam and for adiminstrating a company's AWS account in real life.\n",
    "\n",
    "### Key features of IAM\n",
    "\n",
    "Identity Access Management offers the following features:\n",
    "- centralised control of your AWS account\n",
    "- shared access to your AWS account\n",
    "- granular permissions\n",
    "- identity federeation (including active dir like Facebook, google)\n",
    "- multifactor authentication\n",
    "- provide temporary access for users/ devices and services where necessary\n",
    "- allows you to set up your own password rotation policy\n",
    "- integrates with many different AWS services\n",
    "- supports PCI DSS Compliance (credit card framework)\n",
    "\n",
    "### Key terminology for IAM\n",
    "\n",
    "- Users: \n",
    "    - end users sch as people, employees of an organization etc\n",
    "- Groups:\n",
    "    - a collection of users. Each user in the group will inherit the permissions of the group\n",
    "- Policies:\n",
    "    policies are made up of documents, called policy documents\n",
    "- Policiy Documents:\n",
    "    - documents are in JSON and give permission as to what a User/Group/Role is able to do\n",
    "    \n",
    "- Roles\n",
    "    - you create roles and then assign them to AWS resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Access Management - LAB\n",
    "\n",
    "\n",
    "### Activate multifactor security\n",
    "\n",
    "### Creating an individual IAM group\n",
    "\n",
    "- Create a new user with a unique name\n",
    "- assign user a group by selecting what privileges to add\n",
    "- optional to create tags\n",
    "- can send him an email\n",
    "- can download credentials \n",
    "\n",
    "### Creating a group policy \n",
    "\n",
    "every group starts with no policy and has to be added.\n",
    "\n",
    "All group policies are in JSON format for this case admin access\n",
    "\n",
    "Version: date version\n",
    "Statement\n",
    "    - Effect : Allow\n",
    "    - Action : * this means anything\n",
    "    - Resource: *\n",
    "    \n",
    "### Password policy\n",
    "\n",
    "Can have requirements for password like:\n",
    "- Minimum password length is {12} characters\n",
    "- Require at least one uppercase letter from Latin alphabet (A-Z)\n",
    "- Require at least one lowercase letter from Latin alphabet (a-Z)\n",
    "- Require at least one number\n",
    "- Require at least one non-alphanumeric character (!@#$%^&*()_+-=[]{}|')\n",
    "- Enable password expiration\n",
    "- Password expiration requires administrator reset\n",
    "- Allow users to change their own password\n",
    "- Prevent password reuse\n",
    "\n",
    "In the console you can alter passwords, like deleting or resending password to users.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roles \n",
    "\n",
    "Allow on AWS service to use another AWS service\n",
    "\n",
    "like allows a virtual machine to talk to S3\n",
    "\n",
    "### Exam tips\n",
    "\n",
    "What have we learnt so far?\n",
    "\n",
    "- IAM is universal, it does not apply to regions at this time\n",
    "- the 'root account' is the account created when first setup your AWS account. It has complete Admin access\n",
    "- New users have **NO permissions** when first created\n",
    "- New users are assigned Access Key ID and Secret Access Keys when first created\n",
    "    - Can have programatic access or console access.\n",
    "- These are not the same as a password. you cannot use the access key ID and secret access key to login into the console. you can use this to access AWS via the API's and command line, however\n",
    "- You only get to view these once. if you lose them, you have to regenerate them.\n",
    "- always setup mulltifactor authentication on your root account\n",
    "- you  can create and customise your own password rotation policies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a billing alarm - lab\n",
    "\n",
    "CloudWatch - way to monitor your cloud account\n",
    "\n",
    "- Go into cloud watch create billing\n",
    "- select  create alarm\n",
    "- select metric\n",
    "- select instance to observe\n",
    "- specify metric parameters or conditions\n",
    "- select notification trigger \n",
    "- give it a description \n",
    "- preview and commit\n",
    "\n",
    "in exam, how can you get automatic notifications if account goes over 1,000?\n",
    "\n",
    "You can create a billing alarm in cloud watch, have the billing alarm send a sns topic to email.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 101\n",
    "\n",
    "### What is S3?\n",
    "\n",
    "S3 provides developers and IT teams with secure, durable, highly scalable object storage. Amazon S3 is easy to use, with a simple web services interface to store and retrieve any amount of data from anywhere on the web.\n",
    "\n",
    "### So what is S3?\n",
    "- S3 is a safe place to store your files\n",
    "- it is object-based storage\n",
    "- the data is spread across multiple devices and facilities\n",
    "\n",
    "### The basics of s3 are:\n",
    "- S3 is object-base and allows you to upload files\n",
    "    - Key: or filename of the object\n",
    "    - Value: the data being stored\n",
    "    - Version Id: important for versioning\n",
    "    - Metadata: data about your data\n",
    "    - Subresources:\n",
    "        - access control lists\n",
    "        - torrent \n",
    "    \n",
    "- files can be from 0 Bytes to 5 TB\n",
    "- There is unlimited storage\n",
    "- files are stored in buckets (sort of like folders)\n",
    "- S3 is a universal namespace, that is names must be unique globally\n",
    "    - this is because it creates a web addressed based on its name\n",
    "    - given as https://bucketname.regionlocation.amazonaws.com/\n",
    "- when you upload a file to S3, you will receive a HTPP 2-- code f the upload was successful\n",
    "\n",
    "\n",
    "### How does data consistency work for S3?\n",
    "- Read after write consistency for PUTS of new objects\n",
    "    - if you upload a file to S3, you are able to read it immediately\n",
    "- Eventual consistency for overwrite PUTS and DELETES (can take time to propagate)\n",
    "    - if you change the file, you will have to wait for it to update. will get an eariler version if it is not ready\n",
    "\n",
    "In other words;\n",
    "- if you write a new file and read it immediately aftwards, you will be able to view that data\n",
    "- if you update AN EXISTING file or delete a file and read it immediately, you may get the older version, or you may not. Changes to objects can take time to propagate.\n",
    "\n",
    "S3 has the following guarantees from Amazon;\n",
    "- built for 99.99% availability for the S3 platform\n",
    "- Amazon guarantees 99.95 availability\n",
    "- amazon guarantees 99.99999999% durability for S3 information. thats 11 x9s\n",
    "\n",
    "S3 has the following features;\n",
    "- Tiered storage available\n",
    "- lifecycle management\n",
    "- versioning\n",
    "- encryption\n",
    "- MFA Delete\n",
    "- secure your data using access control lists and bucket policies\n",
    "\n",
    "### S3 storage classes:\n",
    "1. S3 Standard\n",
    "    - 99.99% availability\n",
    "    - 99.999999999% durability\n",
    "    - stored redundantly across multiple devices in multiple facilities, and is designed to sustain the loss of 2 facilities concurrently\n",
    "2. S3 - IA (infrequently Accessed)\n",
    "    - for data that is accessed less frequently, but requires rapid access when needed. Lower fee than S3, but you are charged a retrieval fee\n",
    "3. S3 One Zone -IA\n",
    "    - for where you want a lower-cost option for infrequently access data, but do not require the multiple availability zone data resilience\n",
    "4. S3 - Intelligent Tiering\n",
    "    - optimize costs by automatically moving data to the most cost-effective access tier without performance impact or operational overhead\n",
    "5. S3 Glacier\n",
    "    - a secure, durable and low-cost storage class for data archiving. you can reliably store any amount of data at costs that are competive with or cheaper than on-premises solutions. Retrieval times configurable from minutes to hours.\n",
    "6. S3 Glacier Deep Archive\n",
    "    - S3 lowest-cost storage class where a retrieval time of 12 hours is acceptable.\n",
    "    \n",
    "![Image of S3 tiers](https://raw.githubusercontent.com/JonathanWamsley/AWS-Certified-Solutions-Architect-Associate-2020/master/images/S3%20comparision.JPG)\n",
    "\n",
    "### S3- Charges\n",
    "\n",
    "- storage\n",
    "- requests\n",
    "- storage management pricing\n",
    "- data transfer pricing\n",
    "- transfer acceleration\n",
    "- cross region replication pricing\n",
    "\n",
    "### cross region replication\n",
    "\n",
    "When you upload a file to a bucket in one region and it is automatically replicated to other buckets in other regions\n",
    "\n",
    "### S3 Transfer Acceleration\n",
    "\n",
    "- Amazon S3 Transfer Acceleration enables fast, easy and secure transfers of files over long distances between your end user and S3 buckets.\n",
    "- tranfer acceleration takes advantage of Amazon CloudFront's globally distributed edge locations.\n",
    "    - As the data arrives at an edge location, data is routed to Amazon S3 over an optimized network path\n",
    "  \n",
    "take-away: speeds up time users get a file by accessing local edge locations to retreive data instead of at the source region, which can be much further\n",
    "\n",
    "### Exam Tips\n",
    "\n",
    "- Remember that S3 is Object-based: allows you to upload files\n",
    "- files can be 0 to 5 TB\n",
    "- there is unlimited storage\n",
    "- files are stored in Buckets\n",
    "- S3 is a universtal namespace, that is names must be unique globally\n",
    "- a file can be seen as a bucketname.s3.amazonaws.com in default region\n",
    "- or at other regions, bucketname.regionname.amazonaws.com\n",
    "\n",
    "- not suitable to install an operating system or databsase on, will want block based storage for that. S3 is object based storage\n",
    "\n",
    "- when you successfully upload a file you will get HTTP 200 status code\n",
    "- you can turn on MFA delete\n",
    "\n",
    "The key fundamentals of S3 are:\n",
    "- Key\n",
    "- Value\n",
    "- Version\n",
    "- Metadata\n",
    "- Subresources\n",
    "    - access control lists\n",
    "    - torrent\n",
    "    \n",
    "- read after write consistentcy for PUTS of new objects\n",
    "- eventual consistency for overwrite PUTS and DELETES\n",
    "\n",
    "Storage Classes:\n",
    "- S3 Standard\n",
    "- S3 - IA\n",
    "- S3 - One Zone - IA\n",
    "- S3 - intelligent tiering\n",
    "- S3 - Glacier\n",
    "- S3 - Glacier Deep Archeive\n",
    "\n",
    "Tip read S3 FAQs before taking exam and get hands dirty\n",
    "https://aws.amazon.com/s3/faqs/\n",
    "\n",
    "(will do notes on this later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an S3 Bucket-lab\n",
    "\n",
    "### Steps\n",
    "- go to S3 in the AWS console\n",
    "- create a bucket name(like a file) and it must be unique\n",
    "- select region  \n",
    "\n",
    "**Bucket features that can be turned on**\n",
    "- versioning\n",
    "- service access logging\n",
    "- tags of key/value pairs\n",
    "- object level logging\n",
    "- encryption\n",
    "- cloudwatch to monitor s3\n",
    "\n",
    "### more steps\n",
    "- AWS makes it default to no public access\n",
    "- a summary is shown before you create the bucket\n",
    "\n",
    "- can now go into bucket\n",
    "- upload a file\n",
    "- shows a success (200 status code)\n",
    "- can click on the file and see the overview, properties and permissions\n",
    "\n",
    "Right now the object is not public\n",
    "- go to bucket and edit public access settings \n",
    "- uncheck block all public access\n",
    "- go to file, and change to make public under actions\n",
    "\n",
    "### Overview\n",
    "Can change the bucket storage class in the properties change storage class\n",
    "\n",
    "### Properties\n",
    "To do changes to a bucket as a whole, go to properties tab and change on bucket level.\n",
    "\n",
    "### Permisions\n",
    "The access control list can set access level for each bucket or individual file\n",
    "bucket policies are applied to the whole bucket\n",
    "\n",
    "### Management\n",
    "\n",
    "looks at lifecycle and replication rules\n",
    "\n",
    "There are a lot more features is their S3 Master class\n",
    "\n",
    "### Exam tips\n",
    "\n",
    "Control access to buckets using either a bucket ACL or using Bucket Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 pricing tiers\n",
    "\n",
    "Popular exam question is which tier of S3 should you use for a given scenario?\n",
    "\n",
    "### What makes up the cost of S3?\n",
    "\n",
    "- storage\n",
    "- requests and data retrievals\n",
    "- data transfer\n",
    "- management and replication\n",
    "\n",
    "### What are the different Tiers?\n",
    "\n",
    "Cost decreases per GB , more GB less it cost\n",
    "1. standard\n",
    "2. IA\n",
    "3. one zone - IA\n",
    "4. inteliigent tiering\n",
    "5. glacier\n",
    "6. gllacier deep archive\n",
    "\n",
    "![s3 tier price](https://raw.githubusercontent.com/JonathanWamsley/AWS-Certified-Solutions-Architect-Associate-2020/master/images/S3%20price%20by%20tier.JPG)\n",
    "\n",
    "https://aws.amazon.com/s3/storage-classes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Security and Encryption\n",
    "\n",
    "By default, all newly created buckets are PRIVATE. You can setup access control to your buckets using;\n",
    "\n",
    "- Bucket Policies\n",
    "- Access Control Lists\n",
    "\n",
    "S3 buckets can be configured to create access logs which log all requests made to the S3 bucket. This can be sent to another bucket and even another bucket in another account.\n",
    "\n",
    "### Encryption in transit is archieved by\n",
    "\n",
    "- when you go to a website thats in https, the website is encrypted in transit, that is between your computer and the server.\n",
    "- Achieved by SSL/ TLS (Client Side)\n",
    "- Encryption at rest is (Server Side) encryption of data that is being stored.\n",
    "    - A word document encrypted means others can not read it if the file is taken\n",
    "\n",
    "AWS can only help with Server Side encryption in 3 ways\n",
    "1. S3 Management Keys - SSE-S3 (server side encryption s3)\n",
    "    - amazon manages keys for you(way to encrypt and decrypt file)\n",
    "2. AWS Key Management Service, Managed Keys - SSE KMS\n",
    "    - You and amazon manage keys together\n",
    "3. Server Side Encrpytion with customer provided keys - SSE-C\n",
    "    - Customer give amazon own keys\n",
    "- can also encrypt on the client side. Encrypt then use AWS to put into S3 bucket\n",
    "\n",
    "### Encrypting in AWS console\n",
    "\n",
    "- go into S3\n",
    "- click in bucket\n",
    "- click on file\n",
    "- look at properties, encryption\n",
    "- can change to services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Versioning - Lab\n",
    "\n",
    "Using versioning with S3:\n",
    "- Stores all versions of an object (including all writes and even if you delete an object)\n",
    "- great backup tool\n",
    "- once enabled, versioning cannot be disabled, only suspended\n",
    "- integrates with lifecycle rules\n",
    "- versioning MFA delete capability, which uses multi-factor authentication, can be used to provide an additional layer of security\n",
    "\n",
    "Using the previous public bucket \n",
    "- go to versioning and enable\n",
    "- add another file\n",
    "- edit the file\n",
    "- access of the file is now denied.\n",
    "- make public again\n",
    "- can now see it again\n",
    "- can see versions in bucket name toggling show. shows last modified date, version ID. size and storage clasee\n",
    "\n",
    "To delete\n",
    "- go to actions delete(your folders is now empty) but you can show versions again\n",
    "- has a delete and shows version history\n",
    "- restore by deleting the delete marker\n",
    "- most recent version is now shown\n",
    "\n",
    "\n",
    "### exam tips\n",
    "\n",
    "-stores all versions of an object (including all writes and even if you delete an object)\n",
    "- great backup tool\n",
    "- once enabled, versioning cannot be disabled, only suspended\n",
    "- integrates with lifecycle rules\n",
    "- versioning's MFA delete capability, which uses multi-factor authentication, can be used to provide an additional layer of security\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifecycle management with S3 - LAB\n",
    "\n",
    "in S3 bucket\n",
    "- under management go to lifecycle rule\n",
    "- will automate transitioning your bucket to different tiers of storage\n",
    "- can expire objects as well\n",
    "\n",
    "Creating a lifecycle rule:\n",
    "- enter name of rule\n",
    "- storage class transition\n",
    "    - enable for current version\n",
    "    - enable for previous version\n",
    "    - establish a tier translation in X days\n",
    "- configure expiration\n",
    "    - current version\n",
    "    - prevous version\n",
    "    - clean up expires object delete markers and incomplete multipart uploads\n",
    "        - clean up expired object delete markers (specify days)\n",
    "        - clean up incomplete multipart uploads (specify days)\n",
    "- confirm in summary\n",
    "        \n",
    "### exam tips\n",
    "\n",
    "- automate moving your objects between the different storage tiers\n",
    "- can be used in conjunction with versioning\n",
    "- can be applied to current versions and previous versions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Organizations and Consolidating Billings\n",
    "\n",
    "# What is AWS Orgnaizations?\n",
    "\n",
    "\"AWS Organizations is an account management service that enables you to consolidate multiple AWS accounts into an organization that you create an centrally manage\"\n",
    "\n",
    "\n",
    "![aws organizations](https://docs.aws.amazon.com/organizations/latest/userguide/images/BasicOrganization.png)\n",
    "\n",
    "We have your root AWS account (master account)\n",
    "- best practices are to use this account for billing only\n",
    "- no resources deployed\n",
    "\n",
    "The OU are organizational units\n",
    "- developers, financial department, test, dev, etc\n",
    "- apply permissions by using policies\n",
    "    - applies a policy document that will then be inherited to the OU group\n",
    "    - Allow S3 Bucket, and EC2. Then all branches also have this policy\n",
    "\n",
    "Consolidating billing:\n",
    "- all your accounts are aggregated together\n",
    "- one bill per AWS account\n",
    "- very easy to track charges and allocate costs\n",
    "- volume pricing discount\n",
    "\n",
    "![](http://d1nqddva888cns.cloudfront.net/consolidated_billing_diagram.gif)\n",
    "\n",
    "\n",
    "Watching him use multiple accounts to set up AWS organizations\n",
    "\n",
    "- go into AWS organization in console\n",
    "- create organization (makes you the root account) and give an organization a name\n",
    "- can now invite account (can also create account in master acount)\n",
    "- enter acount email or account id\n",
    "    - will have to have the other account verify that email address\n",
    "    \n",
    "    \n",
    "- from the second account you recieve the invitation that can be accepted\n",
    "- second account has the option to leave the organization\n",
    "\n",
    "\n",
    "- from the master account can now see the 2nd account as the organization name\n",
    "- on the organize accounts tab, you can organize them and give them policies\n",
    "    - can create policies similar to IAM\n",
    "    \n",
    "### Exam tips\n",
    "\n",
    "- always enable MFA on root account\n",
    "- always use a strong and complex password on root account\n",
    "- paying account should be used for billing purposes only. Do not deploy resources into the paying account\n",
    "- enable/disable AWS services using service control policies (SCP) either on OU or on individual accounts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab- Sharing S3 Buckets Across Accounts\n",
    "\n",
    "### 3 different ways to share S3 buckets across accounts\n",
    "\n",
    "- using bucket policies and IAM (applies across the entire bucket), Programmatic access only\n",
    "- Using buckets ACLs and IAM (individual objects). Programmatic access only\n",
    "- cross-account IAM Roles. programatic and console access\n",
    "\n",
    "Roles: a way of temporarily granting access to an AWS resource, either from another AWS service such as EC2 or other AWS accounts\n",
    "\n",
    "starting in aws organizations root account:\n",
    "- go to IAM and select create role\n",
    "    - Select another AWS account\n",
    "    - put the account number of the other account you are giving permision to\n",
    "    - attach policies to the role (AmazonS3FullAccess) with a name\n",
    "    - click into role created\n",
    "        - there is a link that you give to users who can switch role in the console\n",
    "- in second account, go to IAM\n",
    "    - go to users add users (give AWS Management console access)\n",
    "    - (can give custom or autogenerated password)\n",
    "    - add user to group (admin access) and create user\n",
    "\n",
    "- in third account with that new user created with admin access sign in\n",
    "    - has a switch role under the name drop bar\n",
    "    - can use the role that was created in 1st account with the role url link\n",
    "    - shows a cross account access under name\n",
    "    - no permissions for billings (only S3 permission)\n",
    "    - can create a bucket and access previous buckets on account 1\n",
    "    \n",
    "### exam tips\n",
    "\n",
    "3 different ways to share S3 buckets accross acounts\n",
    "\n",
    "- using bucket policies and IAM (across buckets)\n",
    "- using buckets ACLs and IAM (individual objects)\n",
    "- cross-account IAM Roles. (programmatic and console access)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross region replication-lab\n",
    "\n",
    "in AWS console\n",
    "- in buckets, go to management\n",
    "    - to to replication\n",
    "        - add rule (requires versioning to be enabled)\n",
    "            - can select entire bucket or files or (prefix/tags)\n",
    "            - can assign a destination bucket(in this or other account)\n",
    "            - create DNS bucket name and select region (can change ownership/storage class)\n",
    "            - select IAM role and role name\n",
    "- In buckets, you see the replicated bucket but the files are not there\n",
    "- as soon as you make changes to a bucket with cross region replication turn on it will update\n",
    "- upload new file in the original bucket\n",
    "- view new bucket at different region (turn public) and view\n",
    "\n",
    "Note if you delete an original bucket, it does not put a delete marker on the cross region buckets\n",
    "\n",
    "if you delete the latest version in the original bucket, then the cross region still shows the latest version that was deleted in the original bucket\n",
    "\n",
    "### Exam tips\n",
    "\n",
    "- versioning must be enabled on both the source and destination buckets\n",
    "- regions must be unique\n",
    "- files in an existing bucket are not replicated automatically\n",
    "- all subsequent updates files will be replicated automatically\n",
    "- delete markers are not replicated\n",
    "- deleting individual versions or delete markers will not be replicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Transfer Acceleration\n",
    "\n",
    "### what is S3 acceleration\n",
    "\n",
    "S3 transfer accesleration utilises the CloudFront Edge Network to accelerate your uploads to S3. Instead of uploading directly to your S3 bucket, you can use a distinct URL to upload directly to and edge location which will then transfer that file to S3. You will get a distinct URL to upload to:\n",
    "\n",
    "BucketName.s3-accelerate.amazonaws.com\n",
    "\n",
    "So users around the world can upload a file to an edge location that will then upload to our S3 bucket\n",
    "\n",
    "There is a tool to test transfer acceleration\n",
    "https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html\n",
    "\n",
    "compares how much faster it works on world wide regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is CloudFront?\n",
    "\n",
    "### common terms \n",
    "\n",
    "- CloudFront: A content delivery network (CDN) is a system of distributed servers (network) that delivers webpages and other web content to a user based on the geographic locations of the user, the origins of the webpage, and a content delivery server.\n",
    "\n",
    "- Edge Location: this is a location where content will be cached. THis is seperate to an AWS Region/AZ.\n",
    "\n",
    "- Origin: This is the origin of all the files that the CDN will distribute. This can be an S3 Bucket, an EC2 instance, an elastic load balancer or route53\n",
    "\n",
    "- Distribution: this is the name given the CDN which consists of collection of Edge Locations\n",
    "\n",
    "### simple example\n",
    "\n",
    "Without a CDN, a user from lets say Austrailia wants a service in the US would have to pull directly from the US server which can take time.\n",
    "\n",
    "With a CDN, a user from lets say Austrailia wants a service in the US would now connect to an Edge Location if there is a copy of the content on it. If there is no copy then it will download a copy to that location to be cached for (lets say 72 hours). Then if another user grabs that info he will grab the cached version and the time will increase.\n",
    "\n",
    "### Amazon CloudFront features\n",
    "\n",
    "Amazon CloudFront can be used to deliver your entire website, including dynamic, static, streaming, and ineteractive content using a global network of edge locations. Requests for your content are automatically routed to the nearest edge location, so content is delivered with the best possible performance. \n",
    "\n",
    "### Types of distributions\n",
    "\n",
    "- web distribution: typically used for websites\n",
    "- RTMP: used for media streaming\n",
    "\n",
    "### exam tips\n",
    "\n",
    "- Edge Location: this is the location where content will be cached. This is seperate to an AWS Region/AZ\n",
    "- Origin: this is the origin of all the files that the CDN will distribute. This can be either an S3 Bucket, an EC2 instance, and Elastic Load Balancer, or Route53\n",
    "- Distribtion: this is the name given the CDN which consists of a collection of Edge Locations\n",
    "- Web Distribution: typically used for websites\n",
    "- RTMP: used for media streaming\n",
    "- Edge locations are not just READ only, you can write to them too (put an object on them)\n",
    "- obects are cached for the life of the TTL(time to live)\n",
    "-  you can clear cached objects, but you will be charged(can invalidate cached objects at a cost $$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creatingg a CloudFront Distribution - LAB\n",
    "\n",
    "- In S3, will be using a bucket as the origin that will attached the CloudFront distribution to.\n",
    "\n",
    "- In AWS CloudFront distribution (is a global service) click create ditribtion\n",
    "    - can create web distribution (clicks on this one)\n",
    "    - can create RTMP distribtion\n",
    "    \n",
    "- click on origin domain name, which displays all origins\n",
    "    - select the S3 bucket used earlier \n",
    "    - leave everything else default and create\n",
    "- can take time to set up(hour?)\n",
    "- select domain name and copy it, (dtnj0cfnndcgw.cloudfront.net)\n",
    "- go to S3 services\n",
    "- type dtnj0cfnndcgw.cloudfront.net.BucketName into browser to deliver content using edge location\n",
    "- go to cloudfront distribution\n",
    "    - in invalidation\n",
    "    - can invalidate files in the bucket\n",
    "    - go and select then disable it  (takes time)\n",
    "    - go and delete it after its prcoessed\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowball\n",
    "\n",
    "### What is Snowball?\n",
    "\n",
    "- Snowball is a petabyte-scale data transport solution that uses secure appliances to tranfer large amounts of data into and out of AWS (a physical container)\n",
    "- Using Snowball Addresses common challenges with large-scale data transfers including:\n",
    "    - high network costs\n",
    "    - long transfer time\n",
    "    - security conerns\n",
    "- Transferring data with Snowball is:\n",
    "    - simple\n",
    "    - fast\n",
    "    - secure\n",
    "    - can be one-fifth the cost of high-speed internet\n",
    "    \n",
    "### Snowball Info\n",
    "\n",
    "- Comes in 50TB or 80 TB\n",
    "- Uses multiple layers of secuirty designed to protect your data including\n",
    "    - temper-resistent enclosures\n",
    "    - 256-bit encryption\n",
    "    - industry-standard Trusted Platform Module (TPM)\n",
    "        - designed to ensure both secuirty and full chan-of-custody of your data\n",
    "- Once data transfer job has been procced and verified, AWS performs a software erasure of the Snowball appliance\n",
    "\n",
    "\n",
    "### Snowball Edge\n",
    "\n",
    "- comes in 100 TB data\n",
    "- data transfer device with on-board storage and compute capabilities\n",
    "- you can use snowball edge to move large amounts of data into and out of AWS as temporary storage tier for:\n",
    "    - large local datasets\n",
    "    - support local workloads in remote or offline locations\n",
    "\n",
    "(Like having a mini AWS at your disposole)\n",
    "\n",
    "- snowball edge connects to your existing applications and infrastructure using standard storage interfaces, streamlining the data transfer process and minimizing setup and integration.\n",
    "- snowball edge can cluster together to form a local storage tier and process your data on-premises, helping ensure your applications continue to run even when they are not able to access the cloud\n",
    "\n",
    "### What is Snowmobile\n",
    "\n",
    "![lol](https://raw.githubusercontent.com/JonathanWamsley/AWS-Certified-Solutions-Architect-Associate-2020/master/images/AWS%20snowmobile.png)\n",
    "\n",
    "- AWS Snowmobile is an Exabyte-scale data transfer service used to move exremely large amounts of data to AWS.\n",
    "- you can transfer up to 100PB per snowmobile, a 45-foot long ruggedized shipping container, pulled by a semi-trailer truck\n",
    "- snowmobile makes it easy to move massive volumes of data to the cloud including:\n",
    "    - video\n",
    "    - libraries\n",
    "    - image repositories\n",
    "    - complete data center migration\n",
    "- transferring data with snowmobile is secure, fast and cost effective.\n",
    "\n",
    "### When should I use Snowball?\n",
    "\n",
    "![comparison](https://raw.githubusercontent.com/JonathanWamsley/AWS-Certified-Solutions-Architect-Associate-2020/master/images/Snowball%20comparision.JPG)\n",
    "\n",
    "When internet connection is slow and data size is high\n",
    "\n",
    "\n",
    "### exam tips\n",
    "\n",
    "- snowball can:\n",
    "    - import to S3\n",
    "    - export from S3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage Gateway\n",
    "\n",
    "### What is storage gateway?\n",
    "\n",
    "- Storage Gateway: a service that connects an on-premises software applicance with cloudbased storage to provide seamless and secure integration between an organization's on-premises IT enviorment and AWS's storage infrastructure\n",
    "- The service enable you to securely store data to the AWS cloud for scalable and cost-effective storage\n",
    "\n",
    "\n",
    "- Storage gateway's software appliance is available for download as a virtual machine (VM) image that you install on a host in your datacenter\n",
    "- your gateway storage type is asscociated with your aws account through the activation process.\n",
    "\n",
    "\n",
    "### The three different types of storage\n",
    "\n",
    "- file gateway(NFS & SMB)\n",
    "- volume gateway (iSCSI)\n",
    "    - store volumes\n",
    "    - cached volumes\n",
    "- tape gateway (VTL)\n",
    "\n",
    "### file gateway\n",
    "\n",
    "- files are stored as objects in your S3 buckets\n",
    "- accessed through a network file system (NFS) mount point\n",
    "- Ownership, permissions, and timestamps are durably stored in S3 in the user-metadate of the object associated with the file\n",
    "- Once onjects are transferred to S3, they can be managed as native S3 objects, and bucket policies such as versioning, lifecylce management, and cross-region replication apply directly to objects stored in your bucker.\n",
    "\n",
    "\n",
    "### volume gateway\n",
    "\n",
    "- The volume interface presents your applications with disk volumes using the iSCSI block protocol (use virtual hard disk drives)\n",
    "- Data written to these volumes can be a synchronously back up as point-in-time snapshots of your volumes, and stored in the cloud as Amazon EBS snapshots\n",
    "- Snapshots are incremental backups that capture only changed blocks\n",
    "    - All snapshot storage is also compressed to minimize your storage charges. \n",
    "\n",
    "\n",
    "### stored voumes\n",
    "\n",
    "- let you store primary data locally, while asynchronously backing up that data to AWS\n",
    "- stored volumes provide your on-premises applications with low-latency access to their entire dataset while providing durable, off-site backups\n",
    "- data goes from on-premises storage hardware to S3 using EBS snapshots (1GB - 16TB) asynchronously in size\n",
    "\n",
    "![example](https://raw.githubusercontent.com/JonathanWamsley/AWS-Certified-Solutions-Architect-Associate-2020/master/images/storage_gateway_cached_model.png)\n",
    "\n",
    "### cached volumes\n",
    "\n",
    "- cached volume uses S3 as your primary data storage while retaining frequently accessed data locally in your storage gateway\n",
    "- cached volumes minimize the need to scale your on-premise storage infrastructure, while still providing your applications with low-latency access to their frequently accessed data\n",
    "\n",
    "### tape gateway\n",
    "\n",
    "- Tape gateway offers a durable, cost-effective solution to archive your data in the AWS cloud\n",
    "- VTL lets you transfer tape-based backup to virtual tape cartidges on tape gateway\n",
    "\n",
    "\n",
    "### exam tips\n",
    "\n",
    "- file gateway: for flat files, stored directly on S3\n",
    "- volume gateway:\n",
    "    - stored volumes: entire dataset is stored on site and is asynchronously backed up to s3\n",
    "    - cached volumes: entire dataset is stored on S3 and the most frequently accessed data is cached on site\n",
    "- Gateway virtual tape library: used for backup and uses popular backup applications like NetBackup, Backup Exec, Veeam, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Athena vs Macie\n",
    "\n",
    "### What is Athena?\n",
    "\n",
    "- Interactive query service which enables you to analyze and query data located in S3 using stardard SQL\n",
    "\n",
    "- serverless, nothing to provision, pay per query / per TB scanned\n",
    "- No need to set up complex extract/transform/load (ETL) process\n",
    "- works directly with data in S3\n",
    "\n",
    "### what can Athena be used for?\n",
    "\n",
    "- can be used to query log files stored in S3, ELB log, S3 access logs etc\n",
    "- generate business reports on data stored in S3\n",
    "- analyze AWS cost and usage reports\n",
    "- run queries on click-stream data\n",
    "\n",
    "### What is PII (Personally Identifiable Information)?\n",
    "\n",
    "- personal data used to eastablish an individual's identity\n",
    "- the data could be exploted by cimrinals, used in identity theft and financial fraud\n",
    "- home address, email address, SSN\n",
    "- passport number, driver's license number\n",
    "- D.O.B, phone number, bank account, credit card number\n",
    "\n",
    "### What is Macie?\n",
    "\n",
    "Security service which uses Machine Learning and NLP to discover, clasify and protect sensitive data stored in S3\n",
    "\n",
    "- Uses AI to recognize if your S3 objects contain sensitive data such as PIL\n",
    "- dashboards, reporting and alerts\n",
    "- works directly with the data stored in S3\n",
    "- Can also analyze Cloud Trail logs\n",
    "- great for PCI-DDS and preventing ID theft\n",
    "\n",
    "### Athena exam tips\n",
    "\n",
    "- Athena is an interactive query service\n",
    "- it allows you to query data located in S3 using standard SQL\n",
    "- serverless\n",
    "- commonly used to analze log data stored in S3\n",
    "\n",
    "### Macie exam tips\n",
    "\n",
    "- Macie uses AI to analyze data in S3 and helps identify PII\n",
    "- can also be used to analyze CloudTrail logs for suspicious API activity\n",
    "- includes dashboards, reports and alerting\n",
    "- great for PCI-DSS complicance and preventing ID theft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAM  and S3 Summary\n",
    "\n",
    "### IAM\n",
    "- Identify Access Management consist of:\n",
    "    - users\n",
    "    - groups\n",
    "    - roles\n",
    "    - policies\n",
    "- IAM is universal (not region specific)\n",
    "- the root account is the account created when first setup your AWS account with full admin access\n",
    "- new users have no permissions when first created\n",
    "- new users are assigned access key ID and secret access keys when first created\n",
    "    - these are not the same as a password. (use them to access AWS via API's and command line)\n",
    "- you only get to view these once. (have to regenerate them if you lose them)\n",
    "- always set up MFA on root\n",
    "- you can create and customize password rotation policies\n",
    "\n",
    "### S3\n",
    "\n",
    "- S3 is object based\n",
    "- files can be 0-5 TB\n",
    "- there is unlimited storage\n",
    "- files are stored in buckets\n",
    "- S# is a universtal namespace (unique globally)\n",
    "- generates a url with s3-region-amazonaws.com/bucket name \n",
    "- not suitable to install an operating system on\n",
    "- successful uploads will generate a HTTP 200 status code\n",
    "- by default buckets are private\n",
    "    - can be changed with bucket policies\n",
    "    - access control lists\n",
    "- S3 buckets can be configured to create access logs which log all requests made to the S3 bucket. This can be sent to another bucket and even another bucket in another account\n",
    "\n",
    "### Key fundamentals of S3\n",
    "\n",
    "- key (name of the object)\n",
    "- value (storage data values)\n",
    "- version ID\n",
    "- metadata (data about data)\n",
    "- subresources\n",
    "    - access control lists\n",
    "    - torrent\n",
    "- S3 has a read after write consistency for PUTs of new Objects(effective imediately)\n",
    "- S3 has eventual consistentcy for overwrite PUTS and DELETES (can take time to propagate changes)\n",
    "\n",
    "### S3 storage tiers\n",
    "\n",
    "- S3 Standard: 99.99 availability, and 99.999999999 % durability\n",
    "- S3-IA: infrequently Accessed lower storage fee, but charges retrieval fee\n",
    "- S3 One Zone-IA: like S3-IA but in on availability zone so it is cheaper\n",
    "- S3-intelligent tiering: uses ML to move S3 to min cost\n",
    "- S3 Glacier: takes minutes to hours to get data back\n",
    "- S3 Glacier Deep Archive: 12 hours is acceptable timeframe to get data back\n",
    "\n",
    "### Understand how to get the best value out of S3\n",
    "from expensive to least expensive  \n",
    "\n",
    "1. S3 standard\n",
    "2. S3-IA\n",
    "3. S3 - intelligent Tiering (data that can be easily reproduced)\n",
    "4. S3 - one zone -IA\n",
    "5. S3 - Glacier\n",
    "6. S3 - Glacier deep archive \n",
    "\n",
    "### Encryption in transit is achieved by\n",
    "\n",
    "- SSL/TLS (so in Https)\n",
    "- encryption at rest (server side)\n",
    "    - S3 manage keys - SSE-S3\n",
    "    - AWS key management service, managed keys - SSE-KMS\n",
    "    - server side encryption with customers provided keys - SSE-C\n",
    "- client side encrpytion, clients encrypt then upload to S3\n",
    "\n",
    "### Some best practices with AWS Organizations\n",
    "\n",
    "- always enable MFS on root account (use strong complex password)\n",
    "- paying account should be used for billing purposes only. Don ot deploy resources into the paying account\n",
    "- enable/disable AWS services using service control policies (SCP) either on organization units (OU) or on individual accounts\n",
    "\n",
    "### 3 different ways to share S3 buckets across accounts\n",
    "\n",
    "- using bucket policies and IAM (applies across the entire bucket) programmatic access only\n",
    "- Using bucket ACLs and IAM (individual objects) programmatic acces only\n",
    "- cross-account IAM roles. both programmatic and console access\n",
    "\n",
    "### Cross region replications\n",
    "\n",
    "- versioning must be enabled on both the source and destination buckets\n",
    "- regions must be unique\n",
    "- files in an existing buckets are not replicated automatically\n",
    "- all subsequent updated files will be replicated automatically\n",
    "- delete markers are not replicated\n",
    "- deleting individual versions or delete markers will not be replicated\n",
    "\n",
    "### Lifecycle Policies\n",
    "\n",
    "- automates moving your objects between the different storage tiers\n",
    "- can be used in conjunction with versioning\n",
    "- can be applied to current versions and previous verions\n",
    "\n",
    "### transfer accelerations\n",
    "\n",
    "- connects the host region across edge locations\n",
    "- users connect to edge locations instead of the host location\n",
    "- improves speed and performance\n",
    "\n",
    "### Cloudfront\n",
    "\n",
    "- edge location: location where content will be cached. Is serpate to an AWS region/AZ\n",
    "- origin: origin of all files that the CDN will distribute. This can be either S3, and EC2, ELB, or Route53\n",
    "- distribution: name given to CDN containing a collection of edge locations\n",
    "- web distribution: typically used for websites\n",
    "- RTMP: used for media streaming\n",
    "- edge locations are not just read only, you can write to them to\n",
    "- objects are cached for TTL(time to live)\n",
    "- you can clear cached objects but be charged\n",
    "\n",
    "### Snowball\n",
    "\n",
    "Snowball: big physical disk to move data to or from the cloud\n",
    "- snowball can\"\n",
    "    - import to s3\n",
    "    - export to s3\n",
    "    \n",
    "### Storage Gateway\n",
    "\n",
    "- Used for seamlessly transition from on prem to cloud while maintaining live services\n",
    "- File Gateway: for flat files, stored directly on S3\n",
    "- Volume Gateway: \n",
    "    - stored volumes: entire datasert is stored on site and is asynchronously backed up to S3\n",
    "    - cached volumes: entire dataset is stored on S3 and the most frequently accessed data is cached on site\n",
    "- Gateway virtual tape library: used for backup and uses popular backup applications like NetBackup, Backup Exec, Veeam, etc\n",
    "\n",
    "### Athena\n",
    "\n",
    "- Athena is an interactive query service\n",
    "- it allows you to query data located in S3 using standard SQL\n",
    "- serverless\n",
    "- commonly used to analyze log data stored in S3\n",
    "\n",
    "### Macie\n",
    "\n",
    "- Macie uses AI to analyze data in S3 and helps identify PII\n",
    "- can also be used to analze CloudTrail logs for suspicious API activity\n",
    "- includes dashboards, reports and alerting\n",
    "- great for PCI-DSS complicance and preventing ID theft\n",
    "\n",
    "### Examp tip\n",
    "- read the S3 FAQ's before taking the exam. It comes up A LOT!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz\n",
    "\n",
    "### Power User Access allows\n",
    "\n",
    "Access to all AWS services except the management of groups and users within IAM.\n",
    "\n",
    "### You are a security administrator working for a hotel chain. You have a new member of staff who has started as a systems administrator, and she will need full access to the AWS console. You have created the user account and generated the access key id and the secret access key. You have moved this user into the group where the other administrators are, and you have provided the new user with their secret access key and their access key id. However, when she tries to log in to the AWS console, she cannot. Why might that be?\n",
    "\n",
    "You cannot log in to the AWS console using the Access Key ID / Secret Access Key pair. Instead, you must generate a password for the user, and supply the user with this password and your organization's unique AWS console login URL.\n",
    "\n",
    "### You have been asked to advise on a scaling concern. The client has an elegant solution that works well. As the information base grows they use CloudFormation to spin up another stack made up of an S3 bucket and supporting compute instances. The trigger for creating a new stack is when the PUT rate approaches 100 PUTs per second. The problem is that as the business grows that number of buckets is growing into the hundreds and will soon be in the thousands. You have been asked what can be done to reduce the number of buckets without changing the basic architecture.\n",
    "\n",
    "Change the trigger level to around 3000 as S3 can now accommodate much higher PUT and GET levels.\n",
    "\n",
    "Until 2018 there was a hard limit on S3 puts of 100 PUTs per second. To achieve this care needed to be taken with the structure of the name Key to ensure parallel processing. As of July 2018 the limit was raised to 3500 and the need for the Key design was basically eliminated. Disk IOPS is not the issue with the problem. The account limit is not the issue with the problem\n",
    "\n",
    "### What is the default level of access a newly created IAM User is granted?\n",
    "\n",
    "No access to any AWS services.\n",
    "\n",
    "### What is Amazon Glacier?\n",
    "\n",
    "An AWS service designed for long term data archival.\n",
    "\n",
    "### What is the availability of S3-OneZone-IA?\n",
    "\n",
    "99.50%\n",
    "OneZone-IA is only stored in one Zone. While it has the same Durability, it may be less Available than normal S3 or S3-IA.\n",
    "\n",
    "### You are a solutions architect working for a large engineering company that are moving from a legacy infrastructure to AWS. You have configured the company's first AWS account and you have set up IAM. Your company is based in Andorra, but there will be a small subsidiary operating out of South Korea, so that office will need its own AWS environment. Which of the following statements is true?\n",
    "\n",
    "You will need to configure Users and Policy Documents only once, as these are applied globally.\n",
    "\n",
    "### What is the availability of objects stored in S3?\n",
    "\n",
    "99.99%\n",
    "\n",
    "### S3 has eventual consistency for which HTTP Methods?\n",
    "\n",
    "overwrite PUTS and DELETES\n",
    "\n",
    "### What level of access does the \"root\" account have?\n",
    "\n",
    "Administrator Access\n",
    "\n",
    "### What is the minimum file size that I can store on S3?\n",
    "\n",
    "0 bytes\n",
    "\n",
    "### A __________ is a document that provides a formal statement of one or more permissions.\n",
    "\n",
    "Policy\n",
    "\n",
    "### You run a popular photo-sharing website that depends on S3 to store content. Paid advertising is your primary source of revenue. However, you have discovered that other websites are linking directly to the images in your buckets, not to the HTML pages that serve the content. This means that people are not seeing the paid advertising, and you are paying AWS unnecessarily to serve content directly from S3. How might you resolve this issue?\n",
    "\n",
    "Remove the ability for images to be served publicly to the site and then use signed URLs with expiry dates.\n",
    "\n",
    "### One of your users is trying to upload a 7.5GB file to S3. However, they keep getting the following error message: \"Your proposed upload exceeds the maximum allowed object size.\". What solution to this problem does AWS recommend?\n",
    "\n",
    "Design your application to use the Multipart Upload API for all objects.\n",
    "\n",
    "### Every user you create in the IAM systems starts with ________.\n",
    "\n",
    "No Permissions\n",
    "\n",
    "### What is an additional way to secure the AWS accounts of both the root account and new users alike?\n",
    "\n",
    "Implement Multi-Factor Authentication for all accounts.\n",
    "\n",
    "### You run a meme creation website where users can create memes and then download them for use on their own sites. The original images are stored in S3 and each meme's metadata in DynamoDB. You need to decide upon a low-cost storage option for the memes, themselves. If a meme object is unavailable or lost, a Lambda function will automatically recreate it using the original file from S3 and the metadata from DynamoDB. Which storage solution should you use to store the non-critical, easily reproducible memes in the most cost-effective way?\n",
    "\n",
    "S3 - 1Zone-IA\n",
    "\n",
    "S3 - OneZone-IA is the recommended storage for when you want cheaper storage for infrequently accessed objects. It has the same durability but less availability. There can be cost implications if you use it frequently or use it for short lived storage. Glacier is cheaper, but has a long retrieval time.\n",
    "\n",
    "### You are a developer at a fast-growing startup. Until now, you have used the root account to log in to the AWS console. However, as you have taken on more staff, you will need to stop sharing the root account to prevent accidental damage to your AWS infrastructure. What should you do so that everyone can access the AWS resources they need to do their jobs? (Choose 2)\n",
    "\n",
    "Create a customized sign-in link such as \"yourcompany.signin.aws.amazon.com/console\" for your new users to use to sign in with.\n",
    "\n",
    "Create individual user accounts with minimum necessary rights and tell the staff to log in to the console using the credentials provided.\n",
    "\n",
    "Read the AWS Security Best Practice white paper. Also note that the IAM account signin URL is different from the Root account signin URL\n",
    "\n",
    "### The difference between S3 and EBS is that EBS is object-based where as S3 is block-based.\n",
    "\n",
    "False\n",
    "\n",
    "### In what language are policy documents written?\n",
    "\n",
    "JSON\n",
    "\n",
    "### What does S3 stand for?\n",
    "\n",
    "Simple Storage Service\n",
    "\n",
    "### AWS S3 has four different URLs styles that it can be used to access content in S3. The Virtual Hosted Style URL, the Path-Style Access URL, the Static web site URL, and the Legacy Global Endpoint URL. Which of these represents a correct formatting of the Virtual Hosted Style URL style\n",
    "\n",
    "https://my-bucket.s3.us-west-2.amazonaws.com/fastpuppy.csv\n",
    "\n",
    "### Which statement best describes IAM?\n",
    "\n",
    "IAM allows you to manage users, groups, roles, and their corresponding level of access to the AWS Platform.\n",
    "\n",
    "### You work for a busy digital marketing company who currently store their data on-premise. They are looking to migrate to AWS S3 and to store their data in buckets. Each bucket will be named after their individual customers, followed by a random series of letters and numbers. Once written to S3 the data is rarely changed, as it has already been sent to the end customer for them to use as they see fit. However, on some occasions, customers may need certain files updated quickly, and this may be for work that has been done months or even years ago. You would need to be able to access this data immediately to make changes in that case, but you must also keep your storage costs extremely low. The data is not easily reproducible if lost. Which S3 storage class should you choose to minimize costs and to maximize retrieval times?\n",
    "\n",
    "S3 - IA\n",
    "\n",
    "### You have a client who is considering a move to AWS. In establishing a new account, what is the first thing the company should do?\n",
    "\n",
    "Set up an account using their company email address.\n",
    "\n",
    "### Which of the following is not a component of IAM?\n",
    "\n",
    "Organizational Units\n",
    "\n",
    "### You work for a health insurance company that amasses a large number of patients' health records. Each record will be used once when assessing a customer, and will then need to be securely stored for a period of 7 years. In some rare cases, you may need to retrieve this data within 24 hours of a claim being lodged. Given these requirements, which type of AWS storage would deliver the least expensive solution?\n",
    "\n",
    "Glacier\n",
    "\n",
    "### You have created a new AWS account for your company, and you have also configured multi-factor authentication on the root account. You are about to create your new users. What strategy should you consider in order to ensure that there is good security on this account.\n",
    "\n",
    "Enact a strong password policy: user passwords must be changed every 45 days, with each password containing a combination of capital letters, lower case letters, numbers, and special symbols.\n",
    "\n",
    "### A new employee has just started work, and it is your job to give her administrator access to the AWS console. You have given her a user name, an access key ID, a secret access key, and you have generated a password for her. She is now able to log in to the AWS console, but she is unable to interact with any AWS services. What should you do next?\n",
    "\n",
    "Grant her Administrator access by adding her to the Administrators' group.\n",
    "\n",
    "### Using SAML (Security Assertion Markup Language 2.0), you can give your federated users single sign-on (SSO) access to the AWS Management Console.\n",
    "\n",
    "True\n",
    "\n",
    "### S3 has what consistency model for PUTS of new objects\n",
    "\n",
    "Read After Write Consistency\n",
    "\n",
    "### You work for a major news network in Europe. They have just released a new mobile app that allows users to post their photos of newsworthy events in real-time, which are then reviewed by your editors before being copied to your website and made public. Your organization expects this app to grow very quickly, essentially doubling its user base each month. The app uses S3 to store the images, and you are expecting sudden and sizable increases in traffic to S3 when a major news event takes place (as users will be uploading large amounts of content.) You need to keep your storage costs to a minimum, and it does not matter if some objects are lost. With these factors in mind, which storage media should you use to keep costs as low as possible?\n",
    "\n",
    "S3 - One Zone-Infrequent Access\n",
    "\n",
    "### AWS S3 has four different URLs styles that it can be used to access content in S3. The Virtual Hosted Style URL, the Path-Style Access URL, the Static web site URL, and the Legacy Global Endpoint URL. Which of these represents a correct formatting of the Path-Style Access URL style\n",
    "\n",
    "Virtual style puts your bucket name 1st, s3 2nd, and the region 3rd. Path style puts s3 1st and your bucket as a sub domain. Legacy Global endpoint has no region. S3 static hosting can be your own domain or your bucket name 1st, s3-website 2nd, followed by the region. AWS are in the process of phasing out Path style, and support for Legacy Global Endpoint format is limited and discouraged. However it is still useful to be able to recognize them should they show up in logs.\n",
    "\n",
    "### Which of the following is not a feature of IAM?\n",
    "\n",
    "IAM allows you to set up biometric authentication, so that no passwords are required.\n",
    "\n",
    "### You have uploaded a file to S3. Which HTTP code would indicate that the upload was successful?\n",
    "\n",
    "HTTP 200\n",
    "\n",
    "### Which of the following options allows users to have secure access to private files located in S3? (Choose 3)\n",
    "- CloudFront Signed URLs\n",
    "- CloudFront Signed Cookies\n",
    "- CloudFront Origin Access Identity\n",
    "\n",
    "There are three options in the question which can be used to secure access to files stored in S3 and therefore can be considered correct. Signed URLs and Signed Cookies are different ways to ensure that users attempting access to files in an S3 bucket can be authorised. One method generates URLs and the other generates special cookies but they both require the creation of an application and policy to generate and control these items. An Origin Access Identity on the other hand, is a virtual user identity that is used to give the CloudFront distribution permission to fetch a private object from an S3 bucket. Public S3 buckets should never be used unless you are using the bucket to host a public website and therefore this is an incorrect option. \n",
    "\n",
    "### You are a solutions architect who works with a large digital media company. The company has decided that they want to operate within the Japanese region and they need a bucket called \"testbucket\" set up immediately to test their web application on. You log in to the AWS console and try to create this bucket in the Japanese region however you are told that the bucket name is already taken. What should you do to resolve this?\n",
    "\n",
    "Bucket names are global, not regional. This is a popular bucket name and is already taken. You should choose another bucket name.\n",
    "\n",
    "### When you create a new user, that user ________.\n",
    "\n",
    "Will be able to interact with AWS using their access key ID and secret access key using the API, CLI, or the AWS SDKs.\n",
    "\n",
    "### What is AWS Storage Gateway?\n",
    "\n",
    "It is a physical or virtual appliance that can be used to cache S3 locally at a customer's site.\n",
    "\n",
    "### How many S3 buckets can I have per account by default?\n",
    "\n",
    "100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
